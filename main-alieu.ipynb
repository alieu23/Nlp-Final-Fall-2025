{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T17:12:25.559198Z",
     "start_time": "2025-11-21T17:12:10.244897Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "# from  datasets import load_dataset\n",
    "# dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "# train_data = dataset[\"train\"]\n",
    "# test_data = dataset[\"test\"]\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_data.head()\n",
    "# test_data[0]\n",
    "# print(test_data[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  One of the other reviewers has mentioned that ...      1\n",
       "1  A wonderful little production. <br /><br />The...      1\n",
       "2  I thought this was a wonderful way to spend ti...      1\n",
       "3  Basically there's a family where a little boy ...      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:27:53.205083Z",
     "start_time": "2025-11-21T17:12:25.683609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import spacy\n",
    "\n",
    "# ------------------------------\n",
    "# Load API key and spaCy model\n",
    "# ------------------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # NER model\n",
    "\n",
    "# ------------------------------\n",
    "# Normalize text function\n",
    "# ------------------------------\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize(\"NFKC\", text).lower()\n",
    "\n",
    "# ------------------------------\n",
    "# Movie titles\n",
    "# ------------------------------\n",
    "\n",
    "#\n",
    "sample_titles = [\n",
    "   \"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Pulp Fiction\", \"Forrest Gump\",\n",
    "    \"Fight Club\", \"Inception\", \"The Matrix\", \"Goodfellas\", \"The Lord of the Rings: The Return of the King\",\n",
    "    \"Interstellar\", \"Parasite\", \"The Silence of the Lambs\", \"Saving Private Ryan\", \"Schindler’s List\",\n",
    "    \"Gladiator\", \"Titanic\", \"The Green Mile\", \"The Departed\", \"Django Unchained\",\n",
    "    \"The Prestige\", \"Whiplash\", \"The Lion King\", \"Toy Story\", \"Avengers: Endgame\",\n",
    "    \"Avengers: Infinity War\", \"Iron Man\", \"Black Panther\", \"Joker\", \"The Social Network\",\n",
    "    \"The Wolf of Wall Street\", \"La La Land\", \"Mad Max: Fury Road\", \"The Revenant\", \"Get Out\",\n",
    "    \"Oppenheimer\", \"Barbie\", \"Dune\", \"The Batman\", \"Spider-Man: No Way Home\",\n",
    "    \"Everything Everywhere All at Once\", \"The Irishman\", \"12 Years a Slave\", \"Moonlight\", \"Spotlight\",\n",
    "    \"Birdman\", \"Arrival\", \"Blade Runner 2049\", \"No Country for Old Men\", \"The Big Short\",\n",
    "    \"The Hateful Eight\", \"Once Upon a Time in Hollywood\", \"There Will Be Blood\",\n",
    "    \"The Curious Case of Benjamin Button\", \"The Shape of Water\", \"The Theory of Everything\",\n",
    "    \"Bohemian Rhapsody\", \"Rocketman\", \"A Star Is Born\", \"The Imitation Game\", \"The King's Speech\",\n",
    "    \"Slumdog Millionaire\", \"Life of Pi\", \"Gravity\", \"Cast Away\", \"The Truman Show\",\n",
    "    \"Eternal Sunshine of the Spotless Mind\", \"Requiem for a Dream\", \"American Beauty\", \"The Sixth Sense\",\n",
    "    \"Se7en\", \"The Usual Suspects\", \"Memento\", \"Oldboy\", \"Pan’s Labyrinth\",\n",
    "    \"Amélie\", \"The Pianist\", \"The Lives of Others\", \"City of God\", \"Crouching Tiger, Hidden Dragon\",\n",
    "    \"Spirited Away\", \"Howl’s Moving Castle\", \"Princess Mononoke\", \"My Neighbor Totoro\", \"WALL·E\",\n",
    "    \"Up\", \"Inside Out\", \"Coco\", \"Soul\", \"Minari\", \"The Banshees of Inisherin\",\n",
    "    \"Casino Royale\", \"South Park: Bigger, Longer & Uncut\", \"A Fistful of Dollars\", \"Rosemary's Baby\",\n",
    "    \"The Incredibles\", \"Black Swan\", \"Deadpool\", \"The Breakfast Club\", \"The Untouchables\",\n",
    "    \"Shaun of the Dead\", \"True Romance\", \"Harry Potter and the Prisoner of Azkaban\", \"Hot Fuzz\",\n",
    "    \"In Bruges\", \"Boyhood\", \"Straight Outta Compton\", \"Drive\", \"Moneyball\", \"Brazil\", \"Chronicle\",\n",
    "    \"Still Alice\", \"Triangle\", \"The Endless\", \"The Man from Earth\",\n",
    "    \"The Secret in Their Eyes\", \"The Fall\", \"The Hunt\", \"Incendies\", \"The Intouchables\",\n",
    "    \"Prisoners\", \"Enemy\", \"Locke\", \"The Lobster\", \"Under the Skin\",\n",
    "    \"Ex Machina\", \"Annihilation\", \"The Florida Project\", \"Room\", \"Brooklyn\",\n",
    "    \"Carol\", \"The Farewell\", \"Portrait of a Lady on Fire\", \"The Handmaiden\", \"Shoplifters\",\n",
    "    \"A Separation\", \"Toni Erdmann\", \"Cold War\", \"Wild Tales\", \"The Square\"\n",
    "]\n",
    "\n",
    "# normalize titles for regex patterns\n",
    "sample_titles_norm = [normalize_text(t) for t in sample_titles]\n",
    "\n",
    "title_patterns = {\n",
    "    title: re.compile(r\"(?<!\\w)\" + re.escape(title) + r\"(?!\\w)\", re.IGNORECASE)\n",
    "    for title in sample_titles_norm\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# Detect titles function\n",
    "# ------------------------------\n",
    "def detect_titles_regex(text, patterns):\n",
    "    text_norm = normalize_text(text)\n",
    "    detected = []\n",
    "    for title, pattern in patterns.items():\n",
    "        if pattern.search(text_norm):\n",
    "            detected.append(title)\n",
    "    return detected\n",
    "\n",
    "# ------------------------------\n",
    "# TMDb metadata caching\n",
    "# ------------------------------\n",
    "metadata_cache = {}\n",
    "\n",
    "def get_movie_metadata(title):\n",
    "    title_key = title.strip().lower()\n",
    "    if title_key in metadata_cache:\n",
    "        return metadata_cache[title_key]\n",
    "\n",
    "    query_title = title.strip().title()  # proper case for API\n",
    "    search_url = f\"{BASE_URL}/search/movie?api_key={API_KEY}&query={query_title}\"\n",
    "    try:\n",
    "        search_response = requests.get(search_url).json()\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "    if not search_response.get(\"results\"):\n",
    "        return None\n",
    "\n",
    "    movie_id = search_response[\"results\"][0][\"id\"]\n",
    "\n",
    "    credits_url = f\"{BASE_URL}/movie/{movie_id}/credits?api_key={API_KEY}\"\n",
    "    try:\n",
    "        credits_response = requests.get(credits_url).json()\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "    actors = [member[\"name\"] for member in credits_response.get(\"cast\", [])[:7]]\n",
    "    directors = [member[\"name\"] for member in credits_response.get(\"crew\", []) if member[\"job\"] == \"Director\"]\n",
    "\n",
    "    result = {\"actors\": actors, \"directors\": directors}\n",
    "    metadata_cache[title_key] = result\n",
    "    sleep(0.25)  # rate limit\n",
    "    return result\n",
    "\n",
    "# ------------------------------\n",
    "# Enrich with metadata\n",
    "# ------------------------------\n",
    "def enrich_with_metadata(row):\n",
    "    titles = row.get(\"detected_titles\", [])\n",
    "    if not titles:\n",
    "        row[\"actors\"] = None\n",
    "        row[\"directors\"] = None\n",
    "        row[\"ner_entities\"] = []\n",
    "        return row\n",
    "\n",
    "    metadata = get_movie_metadata(titles[0])\n",
    "    row[\"actors\"] = metadata.get(\"actors\") if metadata else []\n",
    "    row[\"directors\"] = metadata.get(\"directors\") if metadata else []\n",
    "\n",
    "    # ------------------------------\n",
    "    # Use spaCy NER to detect persons in review\n",
    "    # ------------------------------\n",
    "    doc = nlp(row[\"text\"])\n",
    "    persons_in_review = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "    # ------------------------------\n",
    "    # Link detected persons to movie metadata\n",
    "    # ------------------------------\n",
    "    relevant_entities = []\n",
    "    for person in persons_in_review:\n",
    "        if person in row[\"actors\"] or person in row[\"directors\"]:\n",
    "            relevant_entities.append(person)\n",
    "\n",
    "    row[\"ner_entities\"] = relevant_entities\n",
    "    return row\n",
    "\n",
    "# ------------------------------\n",
    "# Load dataset\n",
    "# ------------------------------\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Detect titles\n",
    "train_df[\"detected_titles\"] = train_df[\"text\"].apply(lambda x: detect_titles_regex(x, title_patterns))\n",
    "\n",
    "# Filter rows with at least one detected title\n",
    "matched_reviews = train_df[train_df[\"detected_titles\"].map(len) > 0].copy()\n",
    "\n",
    "# Initialize columns\n",
    "matched_reviews[\"actors\"] = None\n",
    "matched_reviews[\"directors\"] = None\n",
    "matched_reviews[\"ner_entities\"] = None\n",
    "\n",
    "# Enrich with metadata and NER\n",
    "matched_reviews = matched_reviews.apply(enrich_with_metadata, axis=1)\n",
    "\n",
    "# ------------------------------\n",
    "# Save final DataFrame - for development purposes\n",
    "# ------------------------------\n",
    "matched_reviews.to_csv(\"matched_reviews_with_metadata_ner.csv\", index=False)\n",
    "print(\"Pipeline complete. Saved matched reviews with NER metadata.\")\n",
    "\n",
    "#Took about 38 minutes to run the full pipeline on the training set.\n"
   ],
   "id": "290f66d74ace2bf9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\PycharmProjects\\Nlp-final-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete. Saved matched reviews with NER metadata.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:27:54.292046Z",
     "start_time": "2025-11-21T17:27:54.267460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered = matched_reviews[matched_reviews[\"detected_titles\"] != \"up\"][10:]\n",
    "filtered.head(10)\n",
    "\n",
    "\n"
   ],
   "id": "2404fef39e00aabc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  label  \\\n",
       "30  Taut and organically gripping, Edward Dmytryk'...      1   \n",
       "33  One of the most significant quotes from the en...      1   \n",
       "35  I bought this film at Blockbuster for $3.00, b...      0   \n",
       "37  Ever watched a movie that lost the plot? Well,...      0   \n",
       "39  After sitting through this pile of dung, my hu...      0   \n",
       "40  It had all the clichés of movies of this type ...      0   \n",
       "41  This movie is based on the book, \"A Many Splen...      1   \n",
       "42  Of all the films I have seen, this one, The Ra...      0   \n",
       "44  This movie struck home for me. Being 29, I rem...      1   \n",
       "47  How this film could be classified as Drama, I ...      0   \n",
       "\n",
       "          detected_titles                                             actors  \\\n",
       "30                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "33                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "35  [requiem for a dream]  [Ellen Burstyn, Jared Leto, Jennifer Connelly,...   \n",
       "37                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "39          [gravity, up]  [Sandra Bullock, George Clooney, Ed Harris, Or...   \n",
       "40                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "41                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "42                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "44                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "47                   [up]  [Ed Asner, Christopher Plummer, Jordan Nagai, ...   \n",
       "\n",
       "             directors ner_entities  \n",
       "30       [Pete Docter]           []  \n",
       "33       [Pete Docter]           []  \n",
       "35  [Darren Aronofsky]           []  \n",
       "37       [Pete Docter]           []  \n",
       "39    [Alfonso Cuarón]           []  \n",
       "40       [Pete Docter]           []  \n",
       "41       [Pete Docter]           []  \n",
       "42       [Pete Docter]           []  \n",
       "44       [Pete Docter]           []  \n",
       "47       [Pete Docter]           []  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>detected_titles</th>\n",
       "      <th>actors</th>\n",
       "      <th>directors</th>\n",
       "      <th>ner_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Taut and organically gripping, Edward Dmytryk'...</td>\n",
       "      <td>1</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>One of the most significant quotes from the en...</td>\n",
       "      <td>1</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I bought this film at Blockbuster for $3.00, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[requiem for a dream]</td>\n",
       "      <td>[Ellen Burstyn, Jared Leto, Jennifer Connelly,...</td>\n",
       "      <td>[Darren Aronofsky]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ever watched a movie that lost the plot? Well,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>After sitting through this pile of dung, my hu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[gravity, up]</td>\n",
       "      <td>[Sandra Bullock, George Clooney, Ed Harris, Or...</td>\n",
       "      <td>[Alfonso Cuarón]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>It had all the clichés of movies of this type ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>This movie is based on the book, \"A Many Splen...</td>\n",
       "      <td>1</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Of all the films I have seen, this one, The Ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>This movie struck home for me. Being 29, I rem...</td>\n",
       "      <td>1</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How this film could be classified as Drama, I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[Ed Asner, Christopher Plummer, Jordan Nagai, ...</td>\n",
       "      <td>[Pete Docter]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "576a8f7600880056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:18.524591Z",
     "start_time": "2025-11-21T17:27:54.361717Z"
    }
   },
   "source": [
    "# Baseline Classification Models without NER Metadata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Prepare data for modeling\n",
    "df = matched_reviews.copy()\n",
    "\n",
    "# Ensure text is string\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]     # 0 = negative, 1 = positive\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20_000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6a4afe24c4746605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:18.865084Z",
     "start_time": "2025-11-21T17:28:18.664067Z"
    }
   },
   "source": [
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_lr = log_reg.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_lr))\n",
    "print(classification_report(y_test, pred_lr))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Logistic Regression ====\n",
      "Accuracy: 0.8583132530120482\n",
      "F1 Score: 0.8579710144927536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      1059\n",
      "           1       0.84      0.87      0.86      1016\n",
      "\n",
      "    accuracy                           0.86      2075\n",
      "   macro avg       0.86      0.86      0.86      2075\n",
      "weighted avg       0.86      0.86      0.86      2075\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b097d143e22dde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:19.123986Z",
     "start_time": "2025-11-21T17:28:18.903141Z"
    }
   },
   "source": [
    "# SVM Model\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_svm = svm_clf.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Linear SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Linear SVM ====\n",
      "Accuracy: 0.8650602409638555\n",
      "F1 Score: 0.8642095053346266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      1059\n",
      "           1       0.85      0.88      0.86      1016\n",
      "\n",
      "    accuracy                           0.87      2075\n",
      "   macro avg       0.87      0.87      0.87      2075\n",
      "weighted avg       0.87      0.87      0.87      2075\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "10057214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:25.763639Z",
     "start_time": "2025-11-21T17:28:19.161648Z"
    }
   },
   "source": [
    "# Baseline Classification Models with NER Metadata\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "def compute_entity_features(row):\n",
    "    titles = row[\"detected_titles\"]\n",
    "\n",
    "    # actors/directors are lists, not strings\n",
    "    actors = row.get(\"actors\", [])\n",
    "    directors = row.get(\"directors\", [])\n",
    "\n",
    "    num_titles = len(titles)\n",
    "    num_actors = len(actors)\n",
    "    num_directors = len(directors)\n",
    "\n",
    "    text = row[\"text\"].lower()\n",
    "\n",
    "    # Count actor mentions\n",
    "    actor_mentions = 0\n",
    "    for a in actors:\n",
    "        actor_mentions += text.count(a.lower())\n",
    "\n",
    "    # Count director mentions\n",
    "    director_mentions = 0\n",
    "    for d in directors:\n",
    "        director_mentions += text.count(d.lower())\n",
    "\n",
    "    # Sentiment toward entity names\n",
    "    entity_tokens = actors + directors\n",
    "    entity_sentiment = 0\n",
    "\n",
    "    if entity_tokens:\n",
    "        combined = \" \".join(entity_tokens)\n",
    "        try:\n",
    "            entity_sentiment = TextBlob(combined).sentiment.polarity\n",
    "        except:\n",
    "            entity_sentiment = 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"num_titles\": num_titles,\n",
    "        \"num_actors\": num_actors,\n",
    "        \"num_directors\": num_directors,\n",
    "        \"actor_mentions\": actor_mentions,\n",
    "        \"director_mentions\": director_mentions,\n",
    "        \"entity_sentiment\": entity_sentiment\n",
    "    })\n",
    "\n",
    "\n",
    "# Compute entity features\n",
    "entity_features = matched_reviews.apply(compute_entity_features, axis=1)\n",
    "full_df = pd.concat([matched_reviews, entity_features], axis=1)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3fd9c56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:25.838685Z",
     "start_time": "2025-11-21T17:28:25.834833Z"
    }
   },
   "source": [
    "# from scipy.sparse import hstack\n",
    "#\n",
    "# # TF-IDF Vectorization on review text with NER features\n",
    "# tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "# X_text = tfidf.fit_transform(full_df[\"text\"])\n",
    "#\n",
    "# X_train_text = tfidf.fit_transform(X_train_text_raw)\n",
    "# X_test_text = tfidf.transform(X_test_text_raw)\n",
    "#\n",
    "# # Combine text features with NER features\n",
    "# X_entity = full_df[[\n",
    "#     \"num_titles\", \"num_actors\", \"num_directors\",\n",
    "#     \"actor_mentions\", \"director_mentions\",\n",
    "#     \"entity_sentiment\"\n",
    "# ]].fillna(0).values\n",
    "#\n",
    "# X = hstack([X_text, X_entity])\n",
    "# y = full_df[\"label\"]\n",
    "#\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:35.646271Z",
     "start_time": "2025-11-21T17:28:25.838685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split BEFORE vectorization\n",
    "X_text_raw = full_df[\"text\"]\n",
    "X_entity = full_df[[\n",
    "    \"num_titles\", \"num_actors\", \"num_directors\",\n",
    "    \"actor_mentions\", \"director_mentions\",\n",
    "    \"entity_sentiment\"\n",
    "]].fillna(0).values\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Train-test split on raw data\n",
    "X_text_train, X_text_test, X_entity_train, X_entity_test, y_train, y_test = train_test_split(\n",
    "    X_text_raw, X_entity, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now fit TF-IDF only on training text\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_text = tfidf.fit_transform(X_text_train)  # Learn from train only\n",
    "X_test_text = tfidf.transform(X_text_test)        # Apply to test\n",
    "\n",
    "# Scale entity features (fit on train, transform both)\n",
    "scaler = StandardScaler(with_mean=False)  # Sparse-compatible\n",
    "X_entity_train_scaled = scaler.fit_transform(X_entity_train)\n",
    "X_entity_test_scaled = scaler.transform(X_entity_test)\n",
    "\n",
    "# Combine features\n",
    "X_train = hstack([X_train_text, X_entity_train])\n",
    "X_test = hstack([X_test_text, X_entity_test])"
   ],
   "id": "c021aeaf1246e003",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b4b9b511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:36.679124Z",
     "start_time": "2025-11-21T17:28:35.710938Z"
    }
   },
   "source": [
    "# Logistic Regression with NER features\n",
    "log_clf = LogisticRegression(max_iter=500)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_log))\n",
    "print(classification_report(y_test, pred_log))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware Logistic Regression ====\n",
      "Accuracy: 0.8674698795180723\n",
      "F1 Score: 0.8659190638712823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1059\n",
      "           1       0.86      0.87      0.87      1016\n",
      "\n",
      "    accuracy                           0.87      2075\n",
      "   macro avg       0.87      0.87      0.87      2075\n",
      "weighted avg       0.87      0.87      0.87      2075\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "8e89465c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:37.353776Z",
     "start_time": "2025-11-21T17:28:36.772104Z"
    }
   },
   "source": [
    "# SVM with NER features\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware SVM ====\n",
      "Accuracy: 0.8665060240963856\n",
      "F1 Score: 0.864812103465105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1059\n",
      "           1       0.86      0.87      0.86      1016\n",
      "\n",
      "    accuracy                           0.87      2075\n",
      "   macro avg       0.87      0.87      0.87      2075\n",
      "weighted avg       0.87      0.87      0.87      2075\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:37.375185Z",
     "start_time": "2025-11-21T17:28:37.353776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # DistilBERT Model for Sentiment Classification\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "# from torch.optim import AdamW\n",
    "# from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "#\n",
    "# # Check for GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Custom Dataset Class\n",
    "# # ------------------------------\n",
    "# class ReviewDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts.iloc[idx])\n",
    "#         label = self.labels.iloc[idx]\n",
    "#\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             return_attention_mask=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'label': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Prepare data\n",
    "# # ------------------------------\n",
    "# # Use the same train-test split as before\n",
    "# X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "#     full_df[\"text\"], full_df[\"label\"],\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=full_df[\"label\"]\n",
    "# )\n",
    "#\n",
    "# # Initialize tokenizer\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#\n",
    "# # Create datasets\n",
    "# train_dataset = ReviewDataset(X_train_text, y_train, tokenizer)\n",
    "# test_dataset = ReviewDataset(X_test_text, y_test, tokenizer)\n",
    "#\n",
    "# # Create dataloaders\n",
    "# batch_size = 16\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Initialize Model\n",
    "# # ------------------------------\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\n",
    "#     'distilbert-base-uncased',\n",
    "#     num_labels=2  # binary classification\n",
    "# )\n",
    "# model.to(device)\n",
    "#\n",
    "# # Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Training Function\n",
    "# # ------------------------------\n",
    "# def train_epoch(model, dataloader, optimizer, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#\n",
    "#     for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "#         optimizer.zero_grad()\n",
    "#\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "#\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "#\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()\n",
    "#\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#     return total_loss / len(dataloader)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Evaluation Function\n",
    "# # ------------------------------\n",
    "# def evaluate(model, dataloader, device):\n",
    "#     model.eval()\n",
    "#     predictions = []\n",
    "#     true_labels = []\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['label'].to(device)\n",
    "#\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask\n",
    "#             )\n",
    "#\n",
    "#             logits = outputs.logits\n",
    "#             preds = torch.argmax(logits, dim=1)\n",
    "#\n",
    "#             predictions.extend(preds.cpu().numpy())\n",
    "#             true_labels.extend(labels.cpu().numpy())\n",
    "#\n",
    "#     return np.array(predictions), np.array(true_labels)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Train the Model\n",
    "# # ------------------------------\n",
    "# num_epochs = 3\n",
    "#\n",
    "# print(\"Starting training...\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "#\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#     print(f\"Average training loss: {train_loss:.4f}\")\n",
    "#\n",
    "#     # Evaluate on test set after each epoch\n",
    "#     predictions, true_labels = evaluate(model, test_loader, device)\n",
    "#     accuracy = accuracy_score(true_labels, predictions)\n",
    "#     f1 = f1_score(true_labels, predictions)\n",
    "#\n",
    "#     print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"Test F1 Score: {f1:.4f}\")\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Final Evaluation\n",
    "# # ------------------------------\n",
    "# print(\"\\n==== DistilBERT Final Results ====\")\n",
    "# predictions, true_labels = evaluate(model, test_loader, device)\n",
    "#\n",
    "# print(\"Accuracy:\", accuracy_score(true_labels, predictions))\n",
    "# print(\"F1 Score:\", f1_score(true_labels, predictions))\n",
    "# print(classification_report(true_labels, predictions))\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Save model (optional)\n",
    "# # ------------------------------\n",
    "# model.save_pretrained(\"./distilbert_sentiment_model\")\n",
    "# tokenizer.save_pretrained(\"./distilbert_sentiment_model\")\n",
    "# print(\"\\nModel saved to ./distilbert_sentiment_model\")"
   ],
   "id": "cbb2a9524f7197fd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-21T17:28:37.454293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TinyBERT Model for Sentiment Classification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Custom Dataset Class\n",
    "# ------------------------------\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ------------------------------\n",
    "# Prepare data\n",
    "# ------------------------------\n",
    "# Use the same train-test split as before\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    full_df[\"text\"], full_df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Initialize TinyBERT tokenizer and model\n",
    "print(\"Loading TinyBERT model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'huawei-noah/TinyBERT_General_4L_312D',\n",
    "    num_labels=2\n",
    ")\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Create datasets (using max_length=256 for faster training)\n",
    "train_dataset = ReviewDataset(X_train_text, y_train, tokenizer, max_length=256)\n",
    "test_dataset = ReviewDataset(X_test_text, y_test, tokenizer, max_length=256)\n",
    "\n",
    "# Create dataloaders (increased batch size for speed)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# ------------------------------\n",
    "# Training Function\n",
    "# ------------------------------\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation Function\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "# ------------------------------\n",
    "# Train the Model\n",
    "# ------------------------------\n",
    "num_epochs = 2  # Reduced to 2 for faster training\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Epochs: {num_epochs}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print('='*50)\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f\"Average training loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on test set after each epoch\n",
    "    predictions, true_labels = evaluate(model, test_loader, device)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Final Evaluation\n",
    "# ------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"==== TinyBERT Final Results ====\")\n",
    "print(\"=\"*50)\n",
    "predictions, true_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# ------------------------------\n",
    "# Save model (optional)\n",
    "# ------------------------------\n",
    "save_model = input(\"\\nSave model? (y/n): \").lower()\n",
    "if save_model == 'y':\n",
    "    model.save_pretrained(\"./tinybert_sentiment_model\")\n",
    "    tokenizer.save_pretrained(\"./tinybert_sentiment_model\")\n",
    "    print(\"Model saved to ./tinybert_sentiment_model\")"
   ],
   "id": "6796bb35475a1b6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading TinyBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Starting training...\n",
      "Training samples: 8297\n",
      "Test samples: 2075\n",
      "Batch size: 32\n",
      "Epochs: 2\n",
      "\n",
      "\n",
      "==================================================\n",
      "Epoch 1/2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 192/260 [18:03<09:10,  8.10s/it]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
